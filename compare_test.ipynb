{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 24 16:42:50 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:01:00.0 Off |                  Off |\n",
      "| 30%   41C    P2    81W / 300W |  11880MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000    Off  | 00000000:21:00.0 Off |                  Off |\n",
      "| 30%   35C    P8    27W / 300W |      8MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000    Off  | 00000000:41:00.0 Off |                  Off |\n",
      "| 30%   36C    P8    29W / 300W |      8MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A6000    Off  | 00000000:42:00.0 Off |                  Off |\n",
      "| 30%   30C    P8    20W / 300W |  36733MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1455      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A    164010      C   /home/benny/venv/bin/python      3379MiB |\n",
      "|    0   N/A  N/A    863176      C   /usr/bin/python3                 8493MiB |\n",
      "|    1   N/A  N/A      1455      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      1455      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A      1455      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A    863176      C   /usr/bin/python3                36725MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjonhwa/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import (\n",
    "    Wav2Vec2Config, \n",
    "    BertConfig,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "from torcheval.metrics.functional import multiclass_f1_score, multiclass_accuracy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import ETRIDataset\n",
    "from models import CASEmodel, RoCASEmodel, CompressedCCEModel, ConcatModel, MultiModalMixer\n",
    "from utils import audio_embedding, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# -- Choose Pretrained Model\n",
    "parser.add_argument(\"--lm_path\", type=str, default=\"klue/bert-base\", help=\"You can choose models among (klue-bert series and klue-roberta series) (default: klue/bert-base\")\n",
    "parser.add_argument(\"--am_path\", type=str, default=\"kresnik/wav2vec2-large-xlsr-korean\")\n",
    "\n",
    "# -- Training Argument\n",
    "parser.add_argument(\"--test_bsz\", type=int, default=16)\n",
    "parser.add_argument(\"--context_max_len\", type=int, default=128)\n",
    "parser.add_argument(\"--audio_max_len\", type=int, default=1024)\n",
    "parser.add_argument(\"--num_labels\", type=int, default=7)\n",
    "parser.add_argument(\"--audio_emb_type\", type=str, default=\"last_hidden_state\", help=\"Can chosse audio embedding type between 'last_hidden_state' and 'extract_features' (default: last_hidden_state)\")\n",
    "parser.add_argument(\"--model\", type=str, default=\"CASE\")\n",
    "\n",
    "## -- directory\n",
    "parser.add_argument(\"--data_path\", type=str, default=\"data/test.csv\")\n",
    "parser.add_argument(\"--model_path\", type=str, default=\"save/epoch:1_CASEmodel.pt\")\n",
    "###### emb_train에 대한 설명 부과하기\n",
    "parser.add_argument(\"--embedding_path\", type=str, default=\"data/emb_test.pt\")\n",
    "\n",
    "# -- utils\n",
    "parser.add_argument(\"--device\", type=str, default=\"cuda:0\")\n",
    "parser.add_argument(\"--num_workers\", type=int, default=4)\n",
    "parser.add_argument(\"--seed\", type=int, default=0)\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed.seed_setting(args.seed)\n",
    "\n",
    "wav_config = Wav2Vec2Config.from_pretrained(args.am_path)\n",
    "bert_config = BertConfig.from_pretrained(args.lm_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.lm_path)\n",
    "\n",
    "def text_audio_collator(batch):\n",
    "    \n",
    "    return {'audio_emb' : pad_sequence([item['audio_emb'] for item in batch], batch_first=True),\n",
    "            'label' : torch.stack([item['label'] for item in batch]).squeeze(),\n",
    "            'input_ids' :  torch.stack([item['input_ids'] for item in batch]).squeeze(),\n",
    "            'attention_mask' :  torch.stack([item['attention_mask'] for item in batch]).squeeze(),\n",
    "            'token_type_ids' :  torch.stack([item['token_type_ids'] for item in batch]).squeeze()}\n",
    "\n",
    "# args.data_path\n",
    "# args.embedding_path\n",
    "test_data = pd.read_csv(args.data_path)\n",
    "test_data.reset_index(inplace=True)\n",
    "\n",
    "audio_emb = audio_embedding.save_and_load(args.am_path, test_data['audio'].tolist(), args.device, args.embedding_path)\n",
    "\n",
    "label_dict = {'angry':0, 'neutral':1, 'sad':2, 'happy':3, 'disqust':4, 'surprise':5, 'fear':6}\n",
    "test_dataset = ETRIDataset(\n",
    "    audio_embedding = audio_emb, \n",
    "    dataset=test_data, \n",
    "    label_dict = label_dict,\n",
    "    tokenizer = tokenizer,\n",
    "    audio_emb_type = args.audio_emb_type,\n",
    "    max_len = args.context_max_len, \n",
    "    )\n",
    "\n",
    "# Create a DataLoader that batches audio sequences and pads them to a fixed length\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=args.test_bsz,\n",
    "    shuffle=False, \n",
    "    collate_fn=text_audio_collator, \n",
    "    num_workers=args.num_workers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dict = {'Model': [],\n",
    "              'Test_ACC': [],\n",
    "              'Test_M_F1': [],\n",
    "              'Test_W_F1': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_path = [os.path.join(\"save\", path) for path in os.listdir('save') if \"CASE\" in path]\n",
    "\n",
    "for model_path in tqdm(case_path):\n",
    "    model = CASEmodel(args.lm_path, wav_config, bert_config, args.num_labels)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(args.device)\n",
    "    model.eval()\n",
    "\n",
    "    test_output = []\n",
    "    test_label = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pbar = tqdm(test_dataloader)\n",
    "        for _, batch in enumerate(pbar):\n",
    "            label = batch['label'].to(args.device)\n",
    "            audio_tensor = batch['audio_emb'].to(args.device)\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(args.device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(args.device)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(args.device)\n",
    "\n",
    "            output = model(\n",
    "                input_ids, \n",
    "                attention_mask,\n",
    "                token_type_ids,\n",
    "                audio_tensor \n",
    "                )['class_logit']\n",
    "            \n",
    "            test_output.append(output.detach().cpu())\n",
    "            test_label.append(label.detach().cpu())\n",
    "\n",
    "        logits = torch.cat(test_output)\n",
    "        labels = torch.cat(test_label)\n",
    "\n",
    "        test_m_f1 = multiclass_f1_score(logits, labels, \n",
    "                                            num_classes=args.num_labels, \n",
    "                                            average=\"macro\").detach().cpu().item()\n",
    "        test_w_f1 = multiclass_f1_score(logits, labels, \n",
    "                                            num_classes=args.num_labels, \n",
    "                                            average=\"weighted\").detach().cpu().item()\n",
    "        test_acc = multiclass_accuracy(logits, labels, \n",
    "                                            num_classes=args.num_labels).detach().cpu().item()\n",
    "\n",
    "        check_dict['Model'].append(model_path.split(\"/\")[1])\n",
    "        check_dict['Test_ACC'].append(test_acc) \n",
    "        check_dict['Test_M_F1'].append(test_m_f1) \n",
    "        check_dict['Test_W_F1'].append(test_acc)    \n",
    "        \n",
    "        model.to(\"cpu\")\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_path = [os.path.join(\"save\", path) for path in os.listdir('save') if \"CCE\" in path]\n",
    "\n",
    "for model_path in tqdm(cce_path):\n",
    "    model = CompressedCCEModel(args, wav_config, bert_config)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(args.device)\n",
    "    model.eval()\n",
    "\n",
    "    test_output = []\n",
    "    test_label = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pbar = tqdm(test_dataloader)\n",
    "        for _, batch in enumerate(pbar):\n",
    "            label = batch['label'].to(args.device)\n",
    "            audio_tensor = batch['audio_emb'].to(args.device)\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(args.device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(args.device)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(args.device)\n",
    "\n",
    "            output = model(\n",
    "                input_ids, \n",
    "                attention_mask,\n",
    "                token_type_ids,\n",
    "                audio_tensor \n",
    "                )['class_logit']\n",
    "            \n",
    "            test_output.append(output.detach().cpu())\n",
    "            test_label.append(label.detach().cpu())\n",
    "\n",
    "        logits = torch.cat(test_output)\n",
    "        labels = torch.cat(test_label)\n",
    "\n",
    "        test_m_f1 = multiclass_f1_score(logits, labels, \n",
    "                                            num_classes=args.num_labels, \n",
    "                                            average=\"macro\").detach().cpu().item()\n",
    "        test_w_f1 = multiclass_f1_score(logits, labels, \n",
    "                                            num_classes=args.num_labels, \n",
    "                                            average=\"weighted\").detach().cpu().item()\n",
    "        test_acc = multiclass_accuracy(logits, labels, \n",
    "                                            num_classes=args.num_labels).detach().cpu().item()\n",
    "\n",
    "        check_dict['Model'].append(model_path.split(\"/\")[1])\n",
    "        check_dict['Test_ACC'].append(test_acc) \n",
    "        check_dict['Test_M_F1'].append(test_m_f1) \n",
    "        check_dict['Test_W_F1'].append(test_acc)    \n",
    "        \n",
    "        model.to(\"cpu\")\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_check = pd.DataFrame(check_dict)\n",
    "# test_check.to_csv(\"data/score.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dict = {'Model': [],\n",
    "              'Test_ACC': [],\n",
    "              'Test_M_F1': [],\n",
    "              'Test_W_F1': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 161/161 [00:33<00:00,  4.81it/s]\n",
      " 10%|█         | 1/10 [00:37<05:37, 37.47s/it]Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 161/161 [00:32<00:00,  4.88it/s]\n",
      " 20%|██        | 2/10 [01:13<04:54, 36.75s/it]Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 161/161 [00:33<00:00,  4.87it/s]\n",
      " 30%|███       | 3/10 [01:48<04:12, 36.06s/it]Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 161/161 [00:33<00:00,  4.87it/s]\n",
      " 40%|████      | 4/10 [02:24<03:34, 35.68s/it]Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 161/161 [00:33<00:00,  4.83it/s]\n",
      " 50%|█████     | 5/10 [02:59<02:58, 35.72s/it]Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 161/161 [00:33<00:00,  4.83it/s]\n",
      " 60%|██████    | 6/10 [03:35<02:22, 35.60s/it]Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 161/161 [00:33<00:00,  4.82it/s]\n",
      " 70%|███████   | 7/10 [04:10<01:46, 35.55s/it]Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 161/161 [00:33<00:00,  4.81it/s]\n",
      " 80%|████████  | 8/10 [04:46<01:11, 35.67s/it]Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 161/161 [00:33<00:00,  4.81it/s]\n",
      " 90%|█████████ | 9/10 [05:22<00:35, 35.66s/it]Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 161/161 [00:33<00:00,  4.85it/s]\n",
      "100%|██████████| 10/10 [05:57<00:00, 35.78s/it]\n"
     ]
    }
   ],
   "source": [
    "concat_path = [os.path.join(\"save\", path) for path in os.listdir('save') if \"Concat\" in path]\n",
    "\n",
    "for model_path in tqdm(concat_path):\n",
    "    model = ConcatModel(args, wav_config, bert_config)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(args.device)\n",
    "    model.eval()\n",
    "\n",
    "    test_output = []\n",
    "    test_label = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pbar = tqdm(test_dataloader)\n",
    "        for _, batch in enumerate(pbar):\n",
    "            label = batch['label'].to(args.device)\n",
    "            audio_tensor = batch['audio_emb'].to(args.device)\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(args.device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(args.device)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(args.device)\n",
    "\n",
    "            output = model(\n",
    "                input_ids, \n",
    "                attention_mask,\n",
    "                token_type_ids,\n",
    "                audio_tensor \n",
    "                )['class_logit']\n",
    "            \n",
    "            test_output.append(output.detach().cpu())\n",
    "            test_label.append(label.detach().cpu())\n",
    "\n",
    "        logits = torch.cat(test_output)\n",
    "        labels = torch.cat(test_label)\n",
    "\n",
    "        test_m_f1 = multiclass_f1_score(logits, labels, \n",
    "                                            num_classes=args.num_labels, \n",
    "                                            average=\"macro\").detach().cpu().item()\n",
    "        test_w_f1 = multiclass_f1_score(logits, labels, \n",
    "                                            num_classes=args.num_labels, \n",
    "                                            average=\"weighted\").detach().cpu().item()\n",
    "        test_acc = multiclass_accuracy(logits, labels, \n",
    "                                            num_classes=args.num_labels).detach().cpu().item()\n",
    "\n",
    "        check_dict['Model'].append(model_path.split(\"/\")[1])\n",
    "        check_dict['Test_ACC'].append(test_acc) \n",
    "        check_dict['Test_M_F1'].append(test_m_f1) \n",
    "        check_dict['Test_W_F1'].append(test_acc)    \n",
    "        \n",
    "        model.to(\"cpu\")\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 161/161 [00:25<00:00,  6.21it/s]\n",
      " 33%|███▎      | 1/3 [00:28<00:56, 28.08s/it]Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 161/161 [00:25<00:00,  6.23it/s]\n",
      " 67%|██████▋   | 2/3 [00:56<00:27, 28.00s/it]Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 161/161 [00:25<00:00,  6.27it/s]\n",
      "100%|██████████| 3/3 [01:23<00:00, 27.96s/it]\n"
     ]
    }
   ],
   "source": [
    "mmm_path = [os.path.join(\"save\", path) for path in os.listdir('save') if \"MMM\" in path]\n",
    "\n",
    "for model_path in tqdm(mmm_path):\n",
    "    model = MultiModalMixer(args, wav_config, bert_config)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(args.device)\n",
    "    model.eval()\n",
    "\n",
    "    test_output = []\n",
    "    test_label = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pbar = tqdm(test_dataloader)\n",
    "        for _, batch in enumerate(pbar):\n",
    "            label = batch['label'].to(args.device)\n",
    "            audio_tensor = batch['audio_emb'].to(args.device)\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(args.device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(args.device)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(args.device)\n",
    "\n",
    "            output = model(\n",
    "                input_ids, \n",
    "                attention_mask,\n",
    "                token_type_ids,\n",
    "                audio_tensor \n",
    "                )['class_logit']\n",
    "            \n",
    "            test_output.append(output.detach().cpu())\n",
    "            test_label.append(label.detach().cpu())\n",
    "\n",
    "        logits = torch.cat(test_output)\n",
    "        labels = torch.cat(test_label)\n",
    "\n",
    "        test_m_f1 = multiclass_f1_score(logits, labels, \n",
    "                                            num_classes=args.num_labels, \n",
    "                                            average=\"macro\").detach().cpu().item()\n",
    "        test_w_f1 = multiclass_f1_score(logits, labels, \n",
    "                                            num_classes=args.num_labels, \n",
    "                                            average=\"weighted\").detach().cpu().item()\n",
    "        test_acc = multiclass_accuracy(logits, labels, \n",
    "                                            num_classes=args.num_labels).detach().cpu().item()\n",
    "\n",
    "        check_dict['Model'].append(model_path.split(\"/\")[1])\n",
    "        check_dict['Test_ACC'].append(test_acc) \n",
    "        check_dict['Test_M_F1'].append(test_m_f1) \n",
    "        check_dict['Test_W_F1'].append(test_acc)    \n",
    "        \n",
    "        model.to(\"cpu\")\n",
    "        del model\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_check = pd.read_csv(\"data/score.csv\")\n",
    "\n",
    "more = pd.DataFrame(check_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_check = pd.concat([test_check, more], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test_ACC</th>\n",
       "      <th>Test_M_F1</th>\n",
       "      <th>Test_W_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>epoch:8_CASEmodel_shceduler-linear_False.pt</td>\n",
       "      <td>0.880359</td>\n",
       "      <td>0.251900</td>\n",
       "      <td>0.880359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>epoch:5_CASEmodel.pt</td>\n",
       "      <td>0.879969</td>\n",
       "      <td>0.256384</td>\n",
       "      <td>0.879969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>epoch:5_CASEmodel_True.pt</td>\n",
       "      <td>0.879969</td>\n",
       "      <td>0.256384</td>\n",
       "      <td>0.879969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>epoch:3_CCEmodel.pt</td>\n",
       "      <td>0.874903</td>\n",
       "      <td>0.246014</td>\n",
       "      <td>0.874903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>epoch:3_CCEmodel_True.pt</td>\n",
       "      <td>0.874903</td>\n",
       "      <td>0.246014</td>\n",
       "      <td>0.874903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model  Test_ACC  Test_M_F1  \\\n",
       "2   epoch:8_CASEmodel_shceduler-linear_False.pt  0.880359   0.251900   \n",
       "7                          epoch:5_CASEmodel.pt  0.879969   0.256384   \n",
       "8                     epoch:5_CASEmodel_True.pt  0.879969   0.256384   \n",
       "14                          epoch:3_CCEmodel.pt  0.874903   0.246014   \n",
       "18                     epoch:3_CCEmodel_True.pt  0.874903   0.246014   \n",
       "\n",
       "    Test_W_F1  \n",
       "2    0.880359  \n",
       "7    0.879969  \n",
       "8    0.879969  \n",
       "14   0.874903  \n",
       "18   0.874903  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_check[test_check['Test_M_F1'] > 0.24]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
