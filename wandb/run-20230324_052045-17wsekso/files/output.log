Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
  0%|                                                                                                                | 0/20 [00:00<?, ?it/s]
  0%|                                                                                                               | 0/145 [00:00<?, ?it/s]
  0%|                                                                                                                | 0/20 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "main.py", line 108, in <module>
    main()
  File "main.py", line 105, in main
    trainer.train()
  File "/home/popul/work_dir/Emotion-Recognition-in-Conversation/trainer.py", line 28, in train
    self._fit()
  File "/home/popul/work_dir/Emotion-Recognition-in-Conversation/trainer.py", line 56, in _fit
    output = self.model(input_ids,
  File "/home/popul/work_dir/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/popul/work_dir/Emotion-Recognition-in-Conversation/models.py", line 91, in forward
    context_emb = self.bert(input_ids, attention_mask, token_type_ids)[0]
  File "/home/popul/work_dir/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/popul/work_dir/transformers/src/transformers/models/bert/modeling_bert.py", line 974, in forward
    batch_size, seq_length = input_shape
ValueError: too many values to unpack (expected 2)